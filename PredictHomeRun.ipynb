{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be217004-5f68-498c-b198-c3bc5ee057ab",
   "metadata": {},
   "source": [
    "# Predicting Home Runs\n",
    "\n",
    "The goal is to predict the number of home runs MLB players will hit in the upcoming season, culminating in a league-wide leaderboard of predictions. The methodology involves:\n",
    "- Data collection from FanGraphs \n",
    "- Preprocessing including feature engineering, standardization, and handling missing values\n",
    "- Multiple linear regression and machine-learning model development\n",
    "- Evaluation through Root Mean Squared Error (RMSE)\n",
    "- Hyperparameter tuning and further improvements\n",
    "\n",
    "## Import Libraries and Load Dataset\n",
    "The dataset is sourced via the `pybaseball` library, pulling season-level batting stats and metrics from FanGraphs ranging from 2015 to 2024. Aside from the standard counting and rate statistics, advanced plate discipline and Statcast metrics like chase rate and exit velocity are also included. Using `pandas` to load the data into a DataFrame, the final dataset contains 6,370 observations across 320 columns with a total of 1,641 hitters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "531fd1f5-eebd-4c9a-83ea-6e6d8e7fa00a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (6370, 320)\n",
      "Number of Players: 1641\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pybaseball import batting_stats\n",
    "\n",
    "# Batting statistics since 2015 for all positions\n",
    "df = batting_stats(start_season=2015, end_season=2024, qual=1)\n",
    "\n",
    "# Extract pitcher data and ids\n",
    "df_pitchers = batting_stats(start_season=2015, end_season=2024, qual=1, position='p')\n",
    "pitcher_ids = df_pitchers['IDfg'].unique()\n",
    "\n",
    "# Filter out pitchers\n",
    "df = df[~df['IDfg'].isin(pitcher_ids)]\n",
    "\n",
    "columns = df.columns.to_list()\n",
    "rows = df.shape[0]\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Number of Players: {df['IDfg'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7d6dc-0553-4949-947f-05c3880978b5",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "417784e1-5091-460d-99c2-99d5a297910a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDfg</th>\n",
       "      <th>Season</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>AB</th>\n",
       "      <th>PA</th>\n",
       "      <th>H</th>\n",
       "      <th>1B</th>\n",
       "      <th>...</th>\n",
       "      <th>maxEV</th>\n",
       "      <th>HardHit</th>\n",
       "      <th>HardHit%</th>\n",
       "      <th>Events</th>\n",
       "      <th>CStr%</th>\n",
       "      <th>CSW%</th>\n",
       "      <th>xBA</th>\n",
       "      <th>xSLG</th>\n",
       "      <th>xwOBA</th>\n",
       "      <th>L-WAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>15640</td>\n",
       "      <td>2024</td>\n",
       "      <td>Aaron Judge</td>\n",
       "      <td>NYY</td>\n",
       "      <td>32</td>\n",
       "      <td>158</td>\n",
       "      <td>559</td>\n",
       "      <td>704</td>\n",
       "      <td>180</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>117.5</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>391</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.267</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>15640</td>\n",
       "      <td>2022</td>\n",
       "      <td>Aaron Judge</td>\n",
       "      <td>NYY</td>\n",
       "      <td>30</td>\n",
       "      <td>157</td>\n",
       "      <td>570</td>\n",
       "      <td>696</td>\n",
       "      <td>177</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>118.4</td>\n",
       "      <td>246.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>404</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>25764</td>\n",
       "      <td>2024</td>\n",
       "      <td>Bobby Witt Jr.</td>\n",
       "      <td>KCR</td>\n",
       "      <td>24</td>\n",
       "      <td>161</td>\n",
       "      <td>636</td>\n",
       "      <td>709</td>\n",
       "      <td>211</td>\n",
       "      <td>123</td>\n",
       "      <td>...</td>\n",
       "      <td>116.9</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.481</td>\n",
       "      <td>538</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>13611</td>\n",
       "      <td>2018</td>\n",
       "      <td>Mookie Betts</td>\n",
       "      <td>BOS</td>\n",
       "      <td>25</td>\n",
       "      <td>136</td>\n",
       "      <td>520</td>\n",
       "      <td>614</td>\n",
       "      <td>180</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>110.6</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>434</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>10155</td>\n",
       "      <td>2018</td>\n",
       "      <td>Mike Trout</td>\n",
       "      <td>LAA</td>\n",
       "      <td>26</td>\n",
       "      <td>140</td>\n",
       "      <td>471</td>\n",
       "      <td>608</td>\n",
       "      <td>147</td>\n",
       "      <td>80</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.460</td>\n",
       "      <td>352</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.261</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IDfg  Season            Name Team  Age    G   AB   PA    H   1B  ...  \\\n",
       "145  15640    2024     Aaron Judge  NYY   32  158  559  704  180   85  ...   \n",
       "157  15640    2022     Aaron Judge  NYY   30  157  570  696  177   87  ...   \n",
       "321  25764    2024  Bobby Witt Jr.  KCR   24  161  636  709  211  123  ...   \n",
       "166  13611    2018    Mookie Betts  BOS   25  136  520  614  180   96  ...   \n",
       "172  10155    2018      Mike Trout  LAA   26  140  471  608  147   80  ...   \n",
       "\n",
       "     maxEV  HardHit  HardHit%  Events  CStr%   CSW%  xBA  xSLG  xwOBA  L-WAR  \n",
       "145  117.5    238.0     0.609     391  0.146  0.267  NaN   NaN    NaN   11.3  \n",
       "157  118.4    246.0     0.609     404  0.169  0.287  NaN   NaN    NaN   11.4  \n",
       "321  116.9    259.0     0.481     538  0.138  0.236  NaN   NaN    NaN   10.0  \n",
       "166  110.6    217.0     0.500     434  0.220  0.270  NaN   NaN    NaN   10.4  \n",
       "172  118.0    162.0     0.460     352  0.201  0.261  NaN   NaN    NaN    9.5  \n",
       "\n",
       "[5 rows x 320 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f0104-a63a-4056-b4b9-818fa67fc10b",
   "metadata": {},
   "source": [
    "First, we will select a subset of 85 relevent, non-redundant features while renaming several columns to remove text like \"(sc)\" from the name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1cd699c9-eea0-44d7-9b2c-f12a486c22d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Selected Columns: 85\n"
     ]
    }
   ],
   "source": [
    "# Select relevant columns and omit repetitive columns\n",
    "selected_columns = ['IDfg', 'Season', 'Name', 'Team', 'Age', 'G', 'AB', 'PA', 'H', '1B', '2B', '3B', 'HR', 'R', 'RBI',\n",
    "                    'BB', 'IBB', 'SO', 'HBP', 'SF', 'SH', 'GDP', 'SB', 'CS', 'AVG', 'GB', 'FB', 'LD', 'IFFB', 'Pitches',\n",
    "                    'Balls', 'Strikes', 'IFH', 'BU', 'BUH', 'BB%', 'K%', 'BB/K', 'OBP', 'SLG', 'OPS', 'ISO', 'BABIP',\n",
    "                    'GB/FB', 'LD%', 'GB%', 'FB%', 'IFFB%', 'HR/FB', 'IFH%', 'BUH%', 'wOBA', 'wRAA', 'wRC', 'Bat', 'RAR',\n",
    "                    'WAR', 'wRC+', 'O-Swing% (sc)', 'Z-Swing% (sc)', 'Swing% (sc)', 'O-Contact% (sc)', 'Z-Contact% (sc)',\n",
    "                    'Contact% (sc)', 'Zone% (sc)', 'Pull%', 'Cent%', 'Oppo%', 'Soft%', 'Med%', 'Hard%', 'EV', 'LA', \n",
    "                    'Barrels', 'Barrel%', 'maxEV', 'HardHit', 'HardHit%', 'Events', 'CStr%', 'CSW%', 'xBA', 'xSLG', \n",
    "                    'xwOBA', 'L-WAR']\n",
    "\n",
    "# Select columns\n",
    "df = df[selected_columns]\n",
    "\n",
    "# Remove '(sc)' from plate discipline metrics\n",
    "df.columns = df.columns.str.replace(r'\\s*\\(sc\\)', '', regex=True)\n",
    "\n",
    "print(f\"Number of Selected Columns: {len(selected_columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f64993c-3310-4094-b579-8fa512c03d11",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "Next, we will list columns with missing values and drop those with extensive missing data, ensuring a complete or mostly complete dataset for modeling. In this case, several observations appear to have missing values, including `xBA`, `xSLG`, and `xwOBA`, which have significant missing values. Since these metrics are calculated using batted-ball data like exit velocity (`EV`) and launch angle (`LA`), which are included in the dataset, we can remove these columns for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fcd60260-61f1-49a4-998c-8387673215eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O-Swing%': 10, 'Z-Swing%': 3, 'Swing%': 2, 'O-Contact%': 44, 'Z-Contact%': 14, 'Contact%': 3, 'Zone%': 2, 'Pull%': 24, 'Cent%': 24, 'Oppo%': 24, 'Soft%': 24, 'Med%': 24, 'Hard%': 24, 'EV': 32, 'LA': 32, 'Barrels': 2, 'Barrel%': 26, 'maxEV': 32, 'HardHit': 2, 'HardHit%': 26, 'xBA': 6370, 'xSLG': 6370, 'xwOBA': 6370}\n",
      "Observations Removed: 74\n"
     ]
    }
   ],
   "source": [
    "missing_columns = df.isnull().sum()\n",
    "missing_columns = missing_columns[missing_columns > 0]\n",
    "missing_columns_list = missing_columns.to_dict()\n",
    "print(missing_columns_list)\n",
    "\n",
    "# Drop columns with completely missing data\n",
    "df = df.drop(columns=['xBA', 'xSLG', 'xwOBA'])\n",
    "\n",
    "# Drop missing observations\n",
    "df = df.dropna()\n",
    "new_rows = df.shape[0]\n",
    "\n",
    "print(f\"Observations Removed: {rows - new_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a7c32c-8326-4cae-877f-4ffcd7ae879b",
   "metadata": {},
   "source": [
    "### Target Variable\n",
    "Since we want to predict home runs for the following season, the target variable `HR_next` shifts each player’s home run count by one season, representing his home-run total for the next season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "706872f8-cd56-4846-bec9-6341a9ae7511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>HR</th>\n",
       "      <th>HR_next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>2016</td>\n",
       "      <td>26</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>2017</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3280</th>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3281</th>\n",
       "      <td>2019</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>2020</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>2021</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>2022</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>2023</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3286</th>\n",
       "      <td>2024</td>\n",
       "      <td>30</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  HR  HR_next\n",
       "3277    2015   4       26\n",
       "3278    2016  26       22\n",
       "3279    2017  22        2\n",
       "3280    2018   2       19\n",
       "3281    2019  19       15\n",
       "3282    2020  15       16\n",
       "3283    2021  16       33\n",
       "3284    2022  33       33\n",
       "3285    2023  33       30\n",
       "3286    2024  30     <NA>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by player and season to ensure consistency before shifting\n",
    "df = df.sort_values(by=['IDfg', 'Season']).reset_index(drop=True)\n",
    "\n",
    "# Create 'HR_next' by shifting HR column by -1 within each player group\n",
    "df['HR_next'] = df.groupby('IDfg')['HR'].shift(-1).astype('Int64')\n",
    "\n",
    "df[df['Name']=='Corey Seager'][['Season', 'HR', 'HR_next']].sort_values('Season')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d898f49-90d4-4129-84a3-c3579013983a",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "To establish a benchmark for future comparisons, an Ordinary Least Squares (OLS) regression model is built using the `statsmodels` library. This baseline model helps determine the predictive strength of our features without regularization or advanced methods.\n",
    "\n",
    "### Training and Test Sets\n",
    "We prepare the training and test datasets by:\n",
    "- Dropping metadata and non-numeric columns\n",
    "- Excluding rows with missing values in the target variable\n",
    "- Splitting the training and test sets 80/20\n",
    "- Standardizing each feature to ensure consistent scaling\n",
    "\n",
    "### Standardization\n",
    "Scaling the training set using `fit_transform()` prevents the model from \"peeking\" at the test data. Using `.transform()` on the test set applies the identical transformation, relying on the mean and standard deviation derived from the training set to maintain consistency between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f61680d-e197-4252-b6b0-4fc998a819cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Drop irrelevant columns, keep only numeric columns, and drop rows with missing target variable\n",
    "df_model = df.drop(columns=['IDfg', 'Name', 'Team']).select_dtypes(include=[np.number]).dropna(subset=['HR_next'])\n",
    "\n",
    "# Separate the features and target\n",
    "X = df_model.drop(columns=['HR_next'])\n",
    "y = df_model['HR_next']\n",
    "\n",
    "# Convert y to integer type if needed\n",
    "y = y.astype(int)\n",
    "\n",
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled arrays back to DataFrames with the original column names\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# Reset the indices to align with y_train and y_test\n",
    "X_train_scaled = X_train_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76dc83f-6ce4-4dbe-a3fb-37f0d7968e2c",
   "metadata": {},
   "source": [
    "### Model Fitting\n",
    "The OLS model is fitted on the scaled training and target data, which produces the following summary output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f2bc58f0-3f3c-4fd0-99ea-517a0cc8b284",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                HR_next   R-squared:                       0.468\n",
      "Model:                            OLS   Adj. R-squared:                  0.457\n",
      "Method:                 Least Squares   F-statistic:                     42.34\n",
      "Date:                Wed, 06 Nov 2024   Prob (F-statistic):               0.00\n",
      "Time:                        19:53:59   Log-Likelihood:                -12742.\n",
      "No. Observations:                3740   AIC:                         2.564e+04\n",
      "Df Residuals:                    3663   BIC:                         2.612e+04\n",
      "Df Model:                          76                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          9.7535      0.121     80.852      0.000       9.517       9.990\n",
      "Season        -0.7232      0.192     -3.762      0.000      -1.100      -0.346\n",
      "Age           -0.8882      0.135     -6.556      0.000      -1.154      -0.623\n",
      "G             -5.8312      0.584     -9.981      0.000      -6.977      -4.686\n",
      "AB           -66.7795    222.055     -0.301      0.764    -502.143     368.584\n",
      "PA             3.5256     19.611      0.180      0.857     -34.923      41.975\n",
      "H             -2.5612      2.913     -0.879      0.379      -8.273       3.151\n",
      "1B            -3.2392      3.171     -1.022      0.307      -9.455       2.977\n",
      "2B            -0.2936      1.712     -0.171      0.864      -3.651       3.064\n",
      "3B            -0.2372      0.412     -0.576      0.565      -1.045       0.571\n",
      "HR            -2.0551      2.722     -0.755      0.450      -7.391       3.281\n",
      "R              1.1643      0.729      1.597      0.110      -0.265       2.594\n",
      "RBI           -0.0895      0.634     -0.141      0.888      -1.332       1.153\n",
      "BB             0.9770      2.804      0.348      0.728      -4.520       6.474\n",
      "IBB            1.0268      0.245      4.190      0.000       0.546       1.507\n",
      "SO            21.7952     51.102      0.427      0.670     -78.395     121.986\n",
      "HBP            0.0002      0.490      0.000      1.000      -0.960       0.960\n",
      "SF            -0.8520      2.496     -0.341      0.733      -5.745       4.041\n",
      "SH            -0.6633      1.740     -0.381      0.703      -4.075       2.749\n",
      "GDP            0.2567      0.261      0.983      0.326      -0.255       0.769\n",
      "SB            -0.1012      0.216     -0.468      0.640      -0.525       0.323\n",
      "CS             0.1307      0.204      0.642      0.521      -0.269       0.530\n",
      "AVG            3.4608     16.724      0.207      0.836     -29.329      36.251\n",
      "GB            32.7362     76.921      0.426      0.670    -118.077     183.549\n",
      "FB            29.9028     64.707      0.462      0.644     -96.962     156.768\n",
      "LD            14.6968     37.639      0.390      0.696     -59.098      88.492\n",
      "IFFB           0.4256      0.296      1.439      0.150      -0.154       1.005\n",
      "Pitches        0.7077      0.824      0.859      0.390      -0.908       2.323\n",
      "Balls         -0.7935      1.800     -0.441      0.659      -4.322       2.735\n",
      "Strikes        1.5997      1.844      0.868      0.386      -2.016       5.215\n",
      "IFH           -0.1064      0.299     -0.356      0.722      -0.693       0.480\n",
      "BU             1.6696      4.385      0.381      0.703      -6.928      10.267\n",
      "BUH            0.0308      0.364      0.085      0.933      -0.683       0.745\n",
      "BB%            0.6701      0.461      1.452      0.146      -0.235       1.575\n",
      "K%             0.4396      0.344      1.279      0.201      -0.234       1.113\n",
      "BB/K          -0.0941      0.304     -0.309      0.757      -0.691       0.503\n",
      "OBP            2.6941     17.075      0.158      0.875     -30.784      36.172\n",
      "SLG            5.6334     37.887      0.149      0.882     -68.648      79.915\n",
      "OPS          -18.0214     45.793     -0.394      0.694    -107.804      71.762\n",
      "ISO            1.8043     22.261      0.081      0.935     -41.842      45.450\n",
      "BABIP         -1.0012      0.439     -2.281      0.023      -1.862      -0.141\n",
      "GB/FB         -0.1907      0.214     -0.890      0.374      -0.611       0.229\n",
      "LD%           12.3141     16.723      0.736      0.462     -20.473      45.101\n",
      "GB%           18.0078     24.105      0.747      0.455     -29.254      65.269\n",
      "FB%           16.7971     23.681      0.709      0.478     -29.632      63.226\n",
      "IFFB%         -0.3135      0.168     -1.863      0.062      -0.643       0.016\n",
      "HR/FB          0.3072      0.288      1.068      0.285      -0.257       0.871\n",
      "IFH%           0.2983      0.154      1.942      0.052      -0.003       0.599\n",
      "BUH%          -0.0340      0.162     -0.209      0.834      -0.352       0.284\n",
      "wOBA          10.6048      3.182      3.333      0.001       4.367      16.843\n",
      "wRAA           9.3116      1.629      5.715      0.000       6.117      12.506\n",
      "wRC          -23.6108      7.452     -3.168      0.002     -38.222      -9.000\n",
      "Bat            1.1601      1.126      1.031      0.303      -1.047       3.367\n",
      "RAR           -8.0111      4.352     -1.841      0.066     -16.544       0.522\n",
      "WAR            8.5626      4.378      1.956      0.051      -0.021      17.146\n",
      "wRC+          -4.2355      1.884     -2.249      0.025      -7.929      -0.542\n",
      "O-Swing%       0.4065      1.000      0.406      0.685      -1.555       2.368\n",
      "Z-Swing%       0.7903      1.017      0.777      0.437      -1.203       2.784\n",
      "Swing%        -1.7136      1.714     -1.000      0.318      -5.074       1.647\n",
      "O-Contact%     0.4059      0.401      1.012      0.311      -0.380       1.192\n",
      "Z-Contact%     0.2647      0.513      0.516      0.606      -0.741       1.270\n",
      "Contact%       0.7732      1.153      0.671      0.502      -1.487       3.033\n",
      "Zone%         -0.1389      0.427     -0.326      0.745      -0.975       0.697\n",
      "Pull%        -12.9437     22.092     -0.586      0.558     -56.257      30.370\n",
      "Cent%        -10.7954     18.328     -0.589      0.556     -46.729      25.138\n",
      "Oppo%        -11.5357     19.056     -0.605      0.545     -48.897      25.826\n",
      "Soft%         -6.8520     17.874     -0.383      0.701     -41.895      28.191\n",
      "Med%          -8.6597     22.476     -0.385      0.700     -52.726      35.406\n",
      "Hard%         -9.2499     23.195     -0.399      0.690     -54.727      36.227\n",
      "EV             0.0430      0.294      0.146      0.884      -0.534       0.620\n",
      "LA             1.0094      0.340      2.966      0.003       0.342       1.676\n",
      "Barrels        2.1238      0.602      3.530      0.000       0.944       3.303\n",
      "Barrel%        0.7595      0.256      2.965      0.003       0.257       1.262\n",
      "maxEV          0.9391      0.204      4.606      0.000       0.539       1.339\n",
      "HardHit        1.3952      0.826      1.689      0.091      -0.224       3.014\n",
      "HardHit%       0.4259      0.295      1.446      0.148      -0.152       1.004\n",
      "Events        -1.7570     23.821     -0.074      0.941     -48.462      44.948\n",
      "CStr%         -1.2389      0.950     -1.304      0.192      -3.102       0.624\n",
      "CSW%           1.0121      0.929      1.089      0.276      -0.810       2.834\n",
      "L-WAR         -0.6140      1.217     -0.505      0.614      -2.999       1.771\n",
      "==============================================================================\n",
      "Omnibus:                      518.472   Durbin-Watson:                   2.020\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              983.682\n",
      "Skew:                           0.874   Prob(JB):                    2.49e-214\n",
      "Kurtosis:                       4.804   Cond. No.                     1.29e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 6.37e-28. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add a constant to X_train_scaled for statsmodels to include an intercept in the model\n",
    "X_train_scaled = sm.add_constant(X_train_scaled)\n",
    "X_test_scaled = sm.add_constant(X_test_scaled)\n",
    "\n",
    "# Fit the model using statsmodels OLS and print the summary\n",
    "ols_model = sm.OLS(y_train, X_train_scaled).fit()\n",
    "print(ols_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa827924-4a82-467e-acff-b8086abbf853",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "The OLS regression results indicate that the model explains around 45.7% of the variance in next-season home runs (Adj. R-squared = 0.457), suggesting moderate predictive power. Significant predictors include Age (negative), wOBA, max exit velocity, and barrels. As expected, the model exhibits multicollinearity, meaning some predictors are highly correlated, which weakens model's reliability and accuracy. Furthermore, the Omnibus and Jarque-Bera diagnostic tests indicate some non-normality in residuals. Root mean squared error (RMSE) is used to gague the model's accuracy in predicting home runs, and the RMSE scores for the training and test sets are displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a44b563-1de6-4593-9963-0178fc193922",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 7.301087628220538\n",
      "RMSE Test: 7.334820855653133\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# RMSE Train\n",
    "RMSE_train_ols = np.sqrt(mean_squared_error(y_train, ols_model.fittedvalues))\n",
    "\n",
    "# RMSE Test\n",
    "y_pred_ols = ols_model.predict(X_test_scaled)\n",
    "RMSE_test_ols = np.sqrt(mean_squared_error(y_test, y_pred_ols))\n",
    "\n",
    "print(f\"RMSE Train: {RMSE_train_ols}\")\n",
    "print(f\"RMSE Test: {RMSE_test_ols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e3928b-19ba-4a6e-a462-e5c3d0a5925a",
   "metadata": {},
   "source": [
    "The RMSE values for the train (7.30) and test (7.33) sets are quite close, indicating that the model generalizes reasonably well without significant overfitting. The RMSE of around 7.3 means that, on average, the model's predictions for next-season home run totals are off by about 7 home runs. These metrics establish a benchmark with which to compare subsequent models. Any model improvements should aim to reduce this error, enhancing predictive accuracy and demonstrating that the refinements add value over the simple OLS regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0217e0d-7c1c-4f62-bf83-db7f6048e8b0",
   "metadata": {},
   "source": [
    "## Model Improvements\n",
    "\n",
    "### Regularization\n",
    "The regularization technique applied here is elastic net regression, which combines lasso (L1) and ridge (L2) regularization to enhance model performance by controlling for multicollinearity and reducing overfitting. Specifically:\n",
    "- Elastic net parameters: The `alpha` parameter controls the overall strength of regularization, while `L1_wt` balances between L1 and L2 penalties\n",
    "- Refitting: With `refit=True`, the model recalculates coefficients for the selected features post-regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58b89885-8ee6-4f8f-b34c-9397bce6b501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features after Regularization: 30\n",
      "RMSE Train: 7.484559414524934\n",
      "RMSE Test: 7.503121710609439\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled = X_train_scaled.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "reg_model = sm.OLS(y_train, X_train_scaled).fit_regularized(method='elastic_net', alpha=0.1, L1_wt=0.5, refit=True)\n",
    "\n",
    "RMSE_train_reg = np.sqrt(mean_squared_error(y_train, reg_model.fittedvalues))\n",
    "\n",
    "y_pred_reg = reg_model.predict(X_test_scaled)\n",
    "RMSE_test_reg = np.sqrt(mean_squared_error(y_test, y_pred_reg))\n",
    "\n",
    "print(f\"Number of Features after Regularization: {sum(reg_model.params != 0)}\")\n",
    "print(f\"RMSE Train: {RMSE_train_reg}\")\n",
    "print(f\"RMSE Test: {RMSE_test_reg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95071c4-6876-4dab-9f71-20a3aeb1f995",
   "metadata": {},
   "source": [
    "Regularization did not reduce the training or test error, suggesting that regularization potentially removed relevant features. Adjusting the regularization strength or re-evaluating feature importance may help improve the results, however, the model's linear assumptions may not be capturing all the underlying relationships in the data. \n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "With the goal of accuracy in mind, we will use Extreme Gradient Boosting (XGBoost) – a powerful and efficient machine-learning algorithm well-suited for structured data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f252ce5-07ab-4011-ada0-f285eeb756a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE Train: 0.9362434894273352\n",
      "RMSE Test: 7.485095468371326\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize the model\n",
    "xgb_model = xgb.XGBRegressor(seed=42)\n",
    "\n",
    "# Remove constant term from OLS\n",
    "X_train_scaled = X_train_scaled.drop(columns='const', errors='ignore')\n",
    "X_test_scaled = X_test_scaled.drop(columns='const', errors='ignore')\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_xgb_train = xgb_model.predict(X_train_scaled)\n",
    "y_pred_xgb_test = xgb_model.predict(X_test_scaled)\n",
    "\n",
    "RMSE_train_xgb = np.sqrt(mean_squared_error(y_train, y_pred_xgb_train))\n",
    "RMSE_test_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb_test))\n",
    "\n",
    "print(f\"RMSE Train: {RMSE_train_xgb}\")\n",
    "print(f\"RMSE Test: {RMSE_test_xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb45ca-8964-48f8-bebd-69127ca737ea",
   "metadata": {},
   "source": [
    "The high discrepancy between training and test RMSE signals overfitting. To mitigate this, further hyperparameter tuning might be needed to improve generalization and achieve a more balanced performance on both datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69d5b28-b393-4768-89b7-d559f51399d2",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "We can perform hyperparameter tuning to further optimize the model using `GridSearchCV` to fine-tune several parameters:\n",
    "- `max_depth`: Controls tree depth and increases complexity\n",
    "- `n_estimators`: Number of trees to fit\n",
    "- `learning_rate`: Controls how quickly the model adapts\n",
    "- `min_split_loss`: Minimum loss reduction to split a node\n",
    "- `subsample`: Fraction of samples used for training each tree, introducing randomness\n",
    "\n",
    "Multiple XGBoost models are trained with various combinations of these parameters, and each model is evaluated using 3-fold cross-validation, resulting in a trained model with the \"best\" set of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "546f6faa-c342-4c34-b8ee-88ad6201c744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "Best parameters found: {'learning_rate': 0.01, 'max_depth': 3, 'min_split_loss': 5, 'n_estimators': 1000, 'subsample': 0.5}\n",
      "Cross-Validated RMSE: 7.237471947066115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6],\n",
    "    'n_estimators': [100, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'min_split_loss': [0, 1, 5],\n",
    "    'subsample': [0.5, 1],\n",
    "}\n",
    "\n",
    "# Initialize new XGBRegressor with no prior parameters\n",
    "xgb_model = xgb.XGBRegressor(seed=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "xgb_model_tuned = grid_search.best_estimator_\n",
    "\n",
    "print(f\"Best parameters found: {best_params}\")\n",
    "print(f\"Cross-Validated RMSE: {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b372d0f-2ef7-4a23-b072-a1f912dce9cc",
   "metadata": {},
   "source": [
    "The cross-validation process tested 72 combinations of hyperparameters for the XGBoost model, each evaluated across three folds, resulting in 216 total fits. The optimal parameters found were:\n",
    "\n",
    "- `learning_rate`: 0.01, slowing down learning for more gradual improvements\n",
    "- `max_depth`: 3, limiting the depth of each tree and helping to avoid overfitting\n",
    "- `min_split_loss`: 5, requiring a minimum loss reduction for a node to split\n",
    "- `n_estimators`: 1000, a large number of boosting rounds to ensure model convergence\n",
    "- `subsample`: 0.5, using only half of the training samples for each tree improved generalization.\n",
    "\n",
    "The cross-validated RMSE of 7.24 shows that tuning has reduced overfitting and slightly increased the model’s predictive accuracy on unseen data. Below are the RMSE training and test scores for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1c689578-f7f1-45d0-8f2c-b7a314e918bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline RMSE Train: 7.301087628220538\n",
      "Baseline RMSE Test: 7.334820855653133\n",
      "\n",
      "Tuned XGBoost RMSE Train: 6.071578793005435\n",
      "Tuned XGBoost RMSE Test: 7.05256944659387\n",
      "\n",
      "Untuned XGBoost RMSE Train: 0.9362434894273352\n",
      "Untuned XGBoost RMSE Test: 7.485095468371326\n",
      "\n",
      "Regularized OLS RMSE Train: 7.484559414524934\n",
      "Regularized OLS RMSE Test: 7.503121710609439\n"
     ]
    }
   ],
   "source": [
    "# Predictions using the best model\n",
    "y_pred_train_tuned = xgb_model_tuned.predict(X_train_scaled)\n",
    "y_pred_test_tuned = xgb_model_tuned.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE for the best model\n",
    "RMSE_train_xgb_tuned = np.sqrt(mean_squared_error(y_train, y_pred_train_tuned))\n",
    "rmse_test_xgb_tuned = np.sqrt(mean_squared_error(y_test, y_pred_test_tuned))\n",
    "\n",
    "print(f\"Baseline RMSE Train: {RMSE_train_ols}\")\n",
    "print(f\"Baseline RMSE Test: {RMSE_test_ols}\\n\")\n",
    "print(f\"Tuned XGBoost RMSE Train: {RMSE_train_xgb_tuned}\")\n",
    "print(f\"Tuned XGBoost RMSE Test: {rmse_test_xgb_tuned}\\n\")\n",
    "print(f\"Untuned XGBoost RMSE Train: {RMSE_train_xgb}\")\n",
    "print(f\"Untuned XGBoost RMSE Test: {RMSE_test_xgb}\\n\")\n",
    "print(f\"Regularized OLS RMSE Train: {RMSE_train_reg}\")\n",
    "print(f\"Regularized OLS RMSE Test: {RMSE_test_reg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411d188c-efc0-4bca-a47b-f02eaba67126",
   "metadata": {},
   "source": [
    "It's evident that the tuned XGBoost model demonstrates the best balance between training and test errors, reducing overall prediction error and outperforming both the baseline and other alternatives in terms of generalization. This model appears to capture relevant patterns most effectively without overfitting, making it the strongest candidate to generate the projected home run leaderboard.\n",
    "## Projected Leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dbf91aec-211c-45cb-85c4-1c2b3d4df462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Proj HR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shohei Ohtani</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Juan Soto</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Judge</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Witt Jr.</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony Santander</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Yordan Alvarez</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vladimir Guerrero Jr.</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jose Ramirez</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Giancarlo Stanton</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ketel Marte</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kyle Schwarber</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Oneil Cruz</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Matt Chapman</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cal Raleigh</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Marcell Ozuna</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Francisco Lindor</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Matt Olson</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pete Alonso</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Salvador Perez</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Willy Adames</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Name  Proj HR\n",
       "0           Shohei Ohtani       38\n",
       "1               Juan Soto       33\n",
       "2             Aaron Judge       33\n",
       "3          Bobby Witt Jr.       32\n",
       "4       Anthony Santander       31\n",
       "5          Yordan Alvarez       31\n",
       "6   Vladimir Guerrero Jr.       29\n",
       "7            Jose Ramirez       29\n",
       "8       Giancarlo Stanton       28\n",
       "9             Ketel Marte       28\n",
       "10         Kyle Schwarber       27\n",
       "11             Oneil Cruz       27\n",
       "12           Matt Chapman       27\n",
       "13            Cal Raleigh       27\n",
       "14          Marcell Ozuna       26\n",
       "15       Francisco Lindor       26\n",
       "16             Matt Olson       26\n",
       "17            Pete Alonso       26\n",
       "18         Salvador Perez       25\n",
       "19           Willy Adames       25"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2024 = df[df['Season']==2024].copy()\n",
    "\n",
    "features = X.columns.tolist()\n",
    "\n",
    "X_2024 = df_2024[features]\n",
    "X_2024_scaled = scaler.transform(X_2024)\n",
    "\n",
    "df_2024['Proj HR'] = xgb_model_tuned.predict(X_2024_scaled).astype(int)\n",
    "\n",
    "leaderboard = df_2024[['Name', 'Proj HR']].sort_values(by='Proj HR', ascending=False).reset_index(drop=True)\n",
    "\n",
    "leaderboard.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0524153c-f6ee-4530-8494-cce4f15fe6b8",
   "metadata": {},
   "source": [
    "## Further Improvements\n",
    "While the tuned XGBoost model shows promising performance, there are additional steps that could further enhance its accuracy and robustness:\n",
    "- **Feature Engineering**: Adding or refining features could reveal new patterns relevant to home runs. For instance, creating interaction terms or transforming certain features (e.g. Age^2) might improve the model’s ability to capture underlying, nonlinear trends. Other biological factors, like height and weight, or experience level with relation to age could also be included. Bat-tracking data could also prove relevant to power production.\n",
    "\n",
    "- **Time-Based Validation**: Since player performance can vary over time, implementing a time-series cross-validation approach would ensure that the model captures temporal dependencies between seasons better.\n",
    "\n",
    "- **Alternate Ensemble/Deep Learning Methods**: Other algorithms, such as random forests or neural networks, may enhance predictive performance by leveraging each model’s strengths.\n",
    "\n",
    "- **Regularization Tuning**: Fine-tuning regularization parameters within XGBoost, such as L1 and L2 penalties, could help reduce overfitting further. Adjusting these parameters would add more control over the complexity of the model, promoting better generalization.\n",
    "\n",
    "- **Handling Seasonal and Tracking System Changes**: Since MLB tracking systems have evolved (e.g., from Trackman to Hawkeye), including adjustments for these transitions or isolating data by tracking system might help reduce noise introduced by measurement changes.\n",
    "\n",
    "- **Minor League Statistics**: Rookies who have yet to play in the prior season could be incorporated into the model using their minor league statistics, adjusted for the level of play. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
